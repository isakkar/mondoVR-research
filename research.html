<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="color-scheme" content="light dark">
    <title>Research</title>
    <meta name="description" content="MondoVR project">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/theme-toggles@4.10.1/css/expand.min.css">
    <!-- Pico.css -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@picocss/pico@2.1.1/css/pico.min.css">
    <link rel="stylesheet" href="index.css">
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
</head>

<body>
<!-- Header -->
<header class="container">
    <nav>
        <ul>
            <li></li>
        </ul>

        <ul>
            <li><a href="index.html">Overview</a></li>
            <li><a href="research.html">Research</a></li>
            <li><a href="prototype.html">Prototype</a></li>
        </ul>

        <ul>
            <li>
                <button
                        class="theme-toggle"
                        type="button"
                        title="Toggle theme"
                        aria-label="Toggle theme"
                >
                    <svg
                            xmlns="http://www.w3.org/2000/svg"
                            aria-hidden="true"
                            width="1em"
                            height="1em"
                            fill="currentColor"
                            class="theme-toggle__expand"
                            viewBox="0 0 32 32"
                    >
                        <clipPath id="theme-toggle__expand__cutout">
                            <path d="M0-11h25a1 1 0 0017 13v30H0Z" />
                        </clipPath>
                        <g clip-path="url(#theme-toggle__expand__cutout)">
                            <circle cx="16" cy="16" r="8.4" />
                            <path d="M18.3 3.2c0 1.3-1 2.3-2.3 2.3s-2.3-1-2.3-2.3S14.7.9 16 .9s2.3 1 2.3 2.3zm-4.6 25.6c0-1.3 1-2.3 2.3-2.3s2.3 1 2.3 2.3-1 2.3-2.3 2.3-2.3-1-2.3-2.3zm15.1-10.5c-1.3 0-2.3-1-2.3-2.3s1-2.3 2.3-2.3 2.3 1 2.3 2.3-1 2.3-2.3 2.3zM3.2 13.7c1.3 0 2.3 1 2.3 2.3s-1 2.3-2.3 2.3S.9 17.3.9 16s1-2.3 2.3-2.3zm5.8-7C9 7.9 7.9 9 6.7 9S4.4 8 4.4 6.7s1-2.3 2.3-2.3S9 5.4 9 6.7zm16.3 21c-1.3 0-2.3-1-2.3-2.3s1-2.3 2.3-2.3 2.3 1 2.3 2.3-1 2.3-2.3 2.3zm2.4-21c0 1.3-1 2.3-2.3 2.3S23 7.9 23 6.7s1-2.3 2.3-2.3 2.4 1 2.4 2.3zM6.7 23C8 23 9 24 9 25.3s-1 2.3-2.3 2.3-2.3-1-2.3-2.3 1-2.3 2.3-2.3z" />
                        </g>
                    </svg>
                </button>
            </li>
        </ul>
    </nav>
</header>
<!-- ./ Header -->

<!-- Main -->
<main class="container">
    <section id="content-section-1">
        <h2>Research posters</h2>
        <div class="grid">
            <div>
                <figure>
                    <img src="img\poster-feedback.png"
                         alt='
                            Research poster on the subject of emotional feedback.
                            The research question is the following: How does emotional feedback from AI conversational agents in VR language learning environments influence learner motivation and engagement?
                            Introduction:
                                Virtual reality (VR) combined with AI conversational agents creates immersive environments for language learning, where agents go beyond linguistic feedback to provide emotional cues such as encouragement, empathy, or tone adaptation. Research in affective computing suggests that such feedback can enhance engagement, reduce anxiety, and improve motivation, yet evidence remains scattered when applied to VR learning contexts.
                            Research strategy:
                                We searched EBSCOhost and Google Scholar (2020- 2025) using combined keywords related to emotional feedback, VR language learning, conversational agents, and motivation. Only peer-reviewed, full-text, English articles were included.
                            Results:
                                Recent studies show that conversational agents in VR can enhance immersion and support language learning, but few studies specifically examine the effect of emotional feedback on learner motivation and engagement.
                                The articles included in our review highlight the potential of agents capable of expressing or recognizing emotions to create more natural and motivating interactions.
                                However, most research remains limited to general approaches to AI or VR, without fully combining emotions, conversational agents, and language learning.
                                This gap justifies our study, which aims to understand how emotional feedback from AI agents in VR truly influences learner engagement and motivation.
                            References:
                                1. Pan, M., Kitson, A., Wan, H., & Prpa, M. (2024). ELLMA-T: An embodied LLM-agent for supporting English language learning in social VR; DOI 10.48550/arXiv.2410.02406
                                2. Ortega-Ochoa, E., Arguedas, M., & Daradoumis, T. (2024). Empathic pedagogical conversational agents: A systematic literature review. British Journal of Educational Technology; DOI 10.1111/bjet.13413
                                3. Dubiel, M., & Botev, J. (2025). Synthetic speech and affective experience in virtual reality: A scoping review. Empathic Computing; DOI 10.70401/ec.2025.0011
                                4. Llanes-Jurado, J., Gómez-Zaragozá, L., Minissi, M. E., Alcañiz, M., & Marín-Morales, J. (2024). Developing conversational Virtual Humans for social emotion elicitation based on large language models. Expert Systems with Applications; DOI 10.1016/j.eswa.2024.123261
                                5. Mishra, C., Verdonschot, R., Hagoort, P., & Skantze, G. (2023). Real-time emotion generation in human-robot dialogue using large language models. Frontiers in Robotics and AI;  DOI 10.3389/frobt.2023.1271610
                            '
                         style="border-radius: 8px; border: 1px solid black;">
                    <figcaption>
                        The Effect of Emotional Feedback from Conversational Agents
                    </figcaption>
                </figure>
                <details>
                    <summary>Effects on emotional feedback</summary>
                    <ul>
                        <li>Reduction of anxiety</li>
                        <li>Enhanced immersion</li>
                        <li>Increased motivation</li>
                        <li>Multimodal interactions</li>
                        <li>Lack of specific data</li>
                        <li>Technical complexity</li>
                        <li>Generalization of approaches</li>
                        <li>Risk of interaction rejection</li>
                    </ul>
                </details>
            </div>

            <div>
                <figure>
                    <img src="img\poster-agents.png"
                         alt='
                            Research poster on the subject of conversational agents.
                            The research question is the following: To what extent do conversational AI-based agents affect user engagement and performance in a pedagogical context?
                            Introduction:
                                Based on MondoVR which is a VR platform for language learning that simulates a realistic scenario with NPCs that users speak to.
                                Many studies on conversational agents in collaborative settings, agents as peers or assistants in a group task, but in this case, agent as the tutor itself & main interlocutor.
                                There was a shift before & after surge of genAI: historically, agents were limited, as rule-based scripts / retrieval models, so especially limited in pedagogical value.
                                But nowadays, chatbots have become more advanced with LLMs that can generate dynamic, novel, and contextually coherent responses.
                            Research strategy:
                                Using EBSCO to search in research databases: manually searching for papers using specific keywords and limiting the search to papers released within the last 2 years.
                            Searching on IEEXPlore using command search with the expression: ("conversational agent" AND ("teaching" OR "pedagogical") AND "AI") for papers published within the last 3 years.
                            Results:
                                Neural-based models provided a significant leap in generating refined, context-aware responses & more dynamic conversational interaction with virtual agents, making them more realistic and engaging for users.
                                For education, various use cases, but most of them simulate real-world scenarios.
                                In studies, conversational agents mostly have a female-based appearance (around 50% female only, around 30% male & female).
                                Before generative AI, the critical finding was that conversational agents yield learning outcomes comparable to human tutors, but they affect interactions the most (users are more engaged).
                                How learners perceived the agents: high effectiveness & technology acceptance.
                                Found to increase the frequency of students "sharing their thoughts" & "engaging with each others reasoning".
                                Various pedagogical applications:
                                    Cognitive: where the intents are reflective skills, simulate & experience, tend to be deployed as face-to-face systems.
                                	Instructional: where the intents are mainly mentoring & coaching, for face-to-face education.
                                	Pastoral: where the intents are to motivate & inspire, for distance-education.
                            References:
                                1.	Pedagogical AI conversational agents in higher education: a conceptual framework and survey of the state of the art; DOI 10.1007/s11423-025-10447-4
                                2.	Promoting Student Engagement in CSCL through Scaffolds and Generative AI-based Conversational Agent; DOI 10.1109/ICAIE64856.2025.11158054
                                3.	The Effects of Conversational Agents on Human Learning and How We Used  Them: A Systematic Review of Studies Conducted Before Generative AI; DOI 10.1007/s11528-025-01066-0
                                4.	The impact of educational chatbot on student learning experience; DOI 10.1007/s10639-023-12166-w
                                5.	iTutor: Promoting AI Guided Knowledge Interaction in Online Learning; DOI 10.1109/ISET55194.2022.00061
                                6.	Common ground improves learning with conversational agents; DOI 10.1080/0144929X.2025.2541222
                                7.	A learning analytics-based collaborative conversational agent to foster productive dialogue in inquiry learning; DOI 10.1111/jcal.13007
                                8.	Quality Assurance of Generative Dialog Models in an Evolving Conversational Agent Used for Swedish Language Practice; DOI 10.1145/3522664.3528592
                                9.	Revolutionizing Blended Learning: Exploring Current Trends and Future Research Directions in the Era of ChatGPT; DOI 10.1109/ICBIM59872.2023.10303267
                            '
                         style="border-radius: 8px; border: 1px solid black;">
                    <figcaption>
                        The Effect of Conversational Agents in a Pedagogical Context on User Engagement and Performance
                    </figcaption>
                </figure>
                <details>
                    <summary>Effects on performance and engagement</summary>
                    <ul>
                        <li>Provides different perspectives and ideas</li>
                        <li>Can limit problem-solving thinking</li>
                        <li>Limited effect on performance/productivity</li>
                        <li>Provides motivation & limits stress</li>
                        <li>Enhances knowledge acquisition</li>
                        <li>Increase in engagement with others & agent</li>
                        <li>Satisfaction increased by ease of use & resource acquisition</li>
                        <li>Poor agent behavior could affect user enthusiasm</li>
                    </ul>
                </details>
            </div>
        </div>

        <div class="grid">
            <div>
                <figure>
                    <img src="img\poster-ui.png"
                         alt='
                            Research poster on the subject of diegetic UI.
                            The research questions are the following: How do diegetic UI (in-world information) and non-diegetic UI (HUD/menus) differ in their effectiveness for language learning outcomes? And what is the impact of each UI approach on cognitive load (extraneous vs. germane) during language learning tasks in VR?
                            Introduction:
                                Second Language Acquisition (SLA) faces significant challenges in traditional settings, primarily due to limited opportunities for authentic interaction and high cognitive load imposed by explicit instruction.
                                Virtual Reality (VR) has emerged as a transformative technology for SLA, offering immersive environments that can simulate real-world language use.
                                However, the design of User Interfaces (UI) within these VR environments remains a critical, yet under-explored, factor.
                                The effectiveness of VR for language learning hinges on how information is presented to the learner.
                                Poorly designed interfaces can increase extraneous cognitive load, distracting learners from the linguistic content.
                                Conversely, well-designed interfaces can facilitate germane cognitive load, promoting deep learning.
                                This research investigates the impact of two primary UI paradigms:
                                    Diegetic UI: Interface elements that exist within the game world (e.g., a book on a virtual table, a signpost).
                                    Non-Diegetic UI: Interface elements overlaid on the screen, separate from the game world (e.g., Heads-Up Displays (HUDs), floating menus).
                            Research strategy:
                                Search Query: ("Virtual Reality" OR "VR" OR "immersive environment" OR "head-mounted display" OR "HMD") AND ("language learning" OR "second language acquisition" OR "L2 acquisition" OR "foreign language" OR "language education" OR "vocabulary learning") AND ("user interface" OR "UI design" OR "diegetic" OR "non-diegetic" OR "HUD" OR "interaction design" OR "interface paradigm" OR "cognitive load" OR "user experience") AND ("empirical" OR "experiment" OR "study" OR "evaluation")
                                Databases: IEEE Xplore, ACM Digital Library, Scopus, and Web of Science.
                                Filters:
                                    Inclusion: Peer-reviewed empirical studies (2021-2024), full immersive VR (HMD), focus on foreign language learning, explicit mention of UI or interaction design.
                                    Exclusion: Desktop VR, Augmented Reality (AR), non-empirical papers (reviews, position papers), studies lacking cognitive load or learning outcome measures.
                                The initial database search yielded 145 records (IEEE: 45, ACM: 40, Scopus: 35, WOS: 25). After removing 12 duplicates and screening 133 abstracts, 115 records were excluded for not meeting criteria (e.g., lack of empirical data or non-VR focus). A total of 16 full-text articles were assessed for eligibility, and 5 new studies were identified as highly relevant. These were combined with 32 studies from previous systematic reviews, resulting in a final corpus of 37 studies included in this review.
                            State-of-the-Art:
                                RQ1: Diegetic vs. Non-Diegetic UI Effectiveness. The analysis reveals a dichotomy in UI design effectiveness based on the HCI Paradigms (Harrison et al., 2007):
                                Non-Diegetic UI (Tool Paradigm):
                                    Strengths: High efficiency for information retrieval. HUDs and menus allow learners to quickly access vocabulary translations or grammar rules without searching the environment.
                                    Weaknesses: Breaks immersion (presence). Users often report a "disconnect" from the virtual world, treating the experience more like a desktop application than a simulation.
                                    Outcome: Effective for explicit vocabulary drills but less effective for situational awareness and cultural immersion.
                                Diegetic UI (Experience Paradigm):
                                    Strengths: Maintains high immersion and "sense of place." By embedding information into objects (e.g., reading a virtual newspaper to learn words), learners engage in situated learning.
                                    Weaknesses: Can be less discoverable. Learners may miss critical information if they do not interact with the specific object.
                                    Outcome: Superior for transfer of learning to real-world contexts and cultural acquisition.
                                Recent Evidence (2024): Peixoto et al. (2024) highlight that while diegetic Uls support the "Experience Paradigm," a hybrid approach is often necessary to support novice learners who need explicit scaffolding (Tool Paradigm).
                                
                                RQ2: Impact on Cognitive Load. Cognitive Load Theory (CLT) serves as the primary lens for evaluating these interfaces.
                                    Extraneous Load: Non-diegetic elements (HUDs) often impose higher extraneous load by forcing the user to split attention between the 3D world and the 2D overlay (Split-Attention Effect).
                                    Germane Load: Diegetic elements tend to reduce extraneous load by integrating information into the task itself, freeing up cognitive resources for germane load (schema construction).
                                    Theoretical Framework (VR-CCL): Song et al. (2023) proposed the VR- CCL (Virtual Reality - Constructivism and Cognitive Load) framework, which explicitly links constructivist learning environments with cognitive load management. Their model suggests that VR environments must balance "Interactive Resonance" (immersion) with "Cognitive Load Orchestration" to prevent overwhelming learners.
                                    Critical Gap: Prior reviews (Pinto et al., 2021) noted that only 9.4% of studies explicitly measured cognitive workload. This review identifies a rising trend (2023-2024) in using physiological measures (EEG, Eye- tracking) to validate that diegetic Uls significantly lower cognitive effort during complex language tasks.

                                Conclusion of State of the Art
                                    The current state of the art indicates a nuanced evolution in VR language learning design. Rather than a simple binary choice between diegetic and non-diegetic interfaces, recent evidence (Peixoto et al., 2024; Song et al., 2023) supports a Hybrid Design Strategy.
                                    - Shift to Authenticity: There is a clear movement away from generic "gamified" overlays towards diegetic (embedded) interactions to maximize situated learning and cultural immersion.
                                    - The Necessity of Scaffolding: However, non-diegetic elements (HUDs) remain essential for novice learners to provide explicit scaffolding and reduce the cognitive load of information retrieval.
                                    - Optimization Goal: The frontier of research is no longer just "which is better," but how to orchestrate Cognitive Load (as per the VR-CCL framework) by dynamically balancing immersive diegetic tasks with efficient non-diegetic support tools.
                            References:
                                1. Peixoto, B., Goncalves, G., Bessa, M., Bessa, L.C.P., & Melo, M. (2024). Impact of different UI on foreign language learning using iVR. In Proceedings of the 2024 International Conference on Graphics and Interaction (ICGI) (pp. 1-8). IEEE. DOI: 10.1109/ICGI64003.2024.10923812
                                2. Harrison, S., Tatar, D., & Sengers, P. (2007). The three paradigms of HCI. In Alt. Chi. Session at the SIGCHI Conference on Human Factors in Computing Systems (pp. 1-18). San Jose, California, USA.
                                3. Peixoto, B., Pinto, R., Melo, M., Cabral, L., & Bessa, M. (2021). Immersive Virtual Reality for Foreign Language Education: A PRISMA Systematic Review. IEEE Access, 9, 48952-48962. DOI: 10.1109/ACCESS.2021.3068858
                                4. Pinto, R. D., Peixoto, B., Melo, M., Cabral, L., & Bessa, M. (2021). Foreign Language Learning Gamification Using Virtual Reality-A Systematic Review of Empirical Research. Education Sciences, 11(5), 222. DOI: 10.3390/educsci11050222
                                5. Song, C., Shin, S.-Y., & Shin, K.-S. (2023). Optimizing Foreign Language Learning in Virtual Reality: A Comprehensive Theoretical Framework Based on Constructivism and Cognitive Load Theory (VR-CCL). Applied Sciences, 13(23), 12557. DOI: 10.3390/app132312557
                            '
                         style="border-radius: 8px; border: 1px solid black;">
                    <figcaption>
                        Diegetic vs Non-Diegetic UI in VR Language Learning
                    </figcaption>
                </figure>
            </div>
            
            <div></div>
        </div>
    </section>
</main>
<!-- ./ Main -->

<dialog id="lightbox">
    <img id="lightbox-img" src="" alt="Enlarged view">
</dialog>

<!-- Minimal theme switcher -->
<script src="js/minimal-theme-switcher.js"></script>

<!-- Modal -->
<script src="js/modal.js"></script>

<!-- JS -->
<script>
    // Lightbox for image zoom
    document.addEventListener("DOMContentLoaded", () => {
    const lightbox = document.getElementById("lightbox");
    const lightboxImg = document.getElementById("lightbox-img");
    const images = document.querySelectorAll("main img");

    // 1. Open Lightbox
    images.forEach(img => {
        img.addEventListener("click", () => {
            lightboxImg.src = img.src;
            lightbox.showModal();
            // FIX: Force scroll to top instantly
            lightbox.scrollTop = 0; 
        });
    });

    // 2. Close Lightbox (Clicking Background)
    lightbox.addEventListener("click", (e) => {
        if (e.target === lightbox) {
            lightbox.close();
        }
    });

    // 3. Close Lightbox (Clicking the Image itself)
    lightboxImg.addEventListener("click", () => {
        lightbox.close();
    });
});
</script>
</body>
</html>
